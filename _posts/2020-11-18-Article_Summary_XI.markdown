---
title: Article summary XI
---

## Summary
[LeCun et al.(2015)](https://www.nature.com/articles/nature14539) described the process of deep learning, which discoverd intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that were used to compute the representation in each layer from the representation in the previous layer. They focused on supervised learning, and then reviewed the architecture, application, advantage and augmentation of different modules, including multilayer neural network, convolutional neural networks and recurrent neural networks. 

[Angermueller et al.(2016)](https://www.embopress.org/doi/full/10.15252/msb.20156651) discussed recent and forthcoming applications of deep learning, with a focus on applications in regulatory genomics and biological image analysis. Firstly, they provided practical pointers and the necessary background to get started with deep architectures. Secondly, they reviewed current software solutions and gave recommendations for applying them to data. The applications they covered were broad to illustrate differences and commonalities between approaches. Finally, they discussed both the potential and possible pitfalls of deep learning and contrasted these methods to traditional machine learning and classical statistical analysis approaches. 


## Reaction
These two reviews didnâ€™t provide comprehensive background on all technical details about deep learning, but they provided a big structure and general understanding of deep learning. The review by [Angermueller et al.(2016)](https://www.embopress.org/doi/full/10.15252/msb.20156651)  also described some practical setting in computational biology. Now we reached a point where we can store too much data and cannot make full use of them. Deep learning made it possible for the machine to perform complex decision-making tasks and extract information that might appear in the human eye from the previously hidden raw data information. [LeCun et al.(2015)](https://www.nature.com/articles/nature14539) thought deep convolutional nets had brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets had shone light on sequential data such as text and speech. They also thought unsupervised learning model and reinforcement learning might produce impressive results and play a more important role in the future. [Angermueller et al.(2016)](https://www.embopress.org/doi/full/10.15252/msb.20156651) also thought unsupervised learning model was a powerful approach, and suggested using the TensorFlow. In these two reviews, the authors are confident about the future of deep learning. However, there is still a lot of room for improvement, such as how to better train the unsupervised learning model, combine reinforcement learning with other models, etc. 

## Questions
1. The reproducibility and the generalizability?
2. In Computational Biology, which is more used in supervised learning or unsupervised learning?
3. How many decisions in practice use Deep learning?



